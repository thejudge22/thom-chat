<div align="center">
  <h1>nanochat</h1>
  <p><em>Open-source self-hostable chat client for <a href="nano-gpt.com">Nano-GPT</a>.</em></p>
  <p>Test it out at <a href="https://t3.0xgingi.xyz">t3.0xgingi.xyz</a></p>
  <p>Get 25 Free Daily prompts using any nano-gpt subscription model without needing an API key</p>
  <img src="image.png">
</div>

**IMPORTANT** - Rename your thom-chat.db.* files to nanochat.db.*

---

## Changes with this fork

- Convex -> SQLite + Drizzle
- Docker + Docker Compose
- Yarn -> Bun
- Openrouter -> Nano-GPT (nano-gpt.com)
- Theme inspired by T3 Chat
- Nano-GPT Web Search / Deep Search (Linkup / Tavily / Exa / Kagi)
- Nano-GPT Web Scraping when you enter a URL (adds to context)
- Nano-GPT Context Memory (Single Chat)
- Cross-Conversation Memory (All Chats)
- Nano-GPT Image Generation + img2img support
- Nano-GPT Speech-to-Text (Whisper/Wizper/ElevenLabs)
- Passkey support (requires HTTPS)
- Nano-GPT Video Generation
- Selectable System Prompts (Assistants)
- KaraKeep Integration (Thanks to <a href="https://github.com/jcrabapple">jcrabapple</a>)
- Nano-GPT YouTube Transcripts (Thanks to <a href="https://github.com/thejudge22">thejudge22</a>)
- Follow-up Questions - Contextual follow-up question suggestions generated by LLM after each response.
- Configurable System Themes
- Model Performance Tracking and Analytics.
- Projects
- Benchmark Data from artificialanalysis.ai API
- Provider Selection for Models (NanoGPT)
- Nano-GPT Video Generation

## Setup (Docker)

### Installation

- Clone the repository `git clone https://github.com/nanogpt-community/nanochat.git`
- `cd nanochat`
- `cp .env.example .env`
- Edit the .env file with your configuration
- `docker compose up`

## Setup (Bun)

### Installation

- Install Bun (https://bun.sh/)
- Clone the repository `git clone https://github.com/nanogpt-community/nanochat.git`
- `cd nanochat`
- `cp .env.example .env`
- Edit the .env file with your configuration
- `bun install`
- `bun run dev`
- run `npx drizzle-kit push` to upgrade your database schema when new features are added!

## Nginx

Ensure to have the following in your server block if you use nginx:

```
proxy_buffer_size 256k;
proxy_buffers 4 256k;
proxy_busy_buffers_size 256k;
client_max_body_size 50M;
```

---

## Features Overview

### Follow-up Questions

The follow-up questions feature automatically generates 2-3 contextual questions after each AI response. Key details:

- **Generation**: Uses zai-org/GLM-4.5-Air model via Nano-GPT
- **Display**: Shows 1 second after message generation completes
- **Persistence**: Suggestions are stored in the database and shown when loading historical conversations
- **User Control**: Can be toggled on/off in Account Settings
- **Length Check**: Only generates for assistant messages over 100 characters
- **Interaction**: Clicking a suggestion inserts it into the input field
- **Cleanup**: Suggestions are hidden when user sends a new message

### Web Search

Multiple search providers available:

- **Linkup** - Standard and deep web search
- **Tavily** - Optimized for AI applications
- **Exa** - Neural search engine
- **Kagi** - Premium search results

### YouTube Transcripts

Automatically fetch and transcribe YouTube videos when URLs are detected in user messages. Costs $0.01 per transcript.

### Memory Systems

- **Context Memory**: Compresses long conversations within a single chat for better context retention
- **Persistent Memory**: Remembers facts about the user across different conversations

### Assistants

Create custom system prompts with:

- Custom name and instructions
- Default model selection
- Default web search mode
- Web search provider selection

### Image Generation

Generate images using Nano-GPT's image models with support for:

- Text-to-image
- Image-to-image (img2img)

### Text-to-Speech

Listen to assistant messages read aloud using a variety of models:

- **Models**: OpenAI (TTS-1, HD), Kokoro (Multilingual), ElevenLabs (Premium)
- **Controls**: Play/Stop, Speed Control (0.25x - 4.0x)
- **Cost Efficient**: Supports ultra-low cost models like GPT-4o Mini TTS ($0.0006/1k)

### Speech-to-Text

Transcribe voice messages using:

- **Models**: Whisper Large V3 (OpenAI), Wizper (Fast), ElevenLabs
- **Usage**: Click the microphone icon in the chat input
- **Analytics**: Usage and costs are tracked in Model Analytics

### KaraKeep Integration

Save conversations as bookmarks to your KaraKeep instance for long-term storage and organization.

### Model Benchmarks

View performance benchmarks from [Artificial Analysis](https://artificialanalysis.ai) directly in the model picker:

- **For LLMs**: Intelligence Index, Coding Index, Math Index, and Speed (tokens/sec)
- **For Image Models**: ELO rating and Rank
- Benchmarks appear in the model info panel (click the info icon on any model)
- Requires `ARTIFICIAL_ANALYSIS_API_KEY` environment variable

### Provider Selection

For models supported by multiple providers on NanoGPT, you can:
- Select a specific provider (e.g., 'openai', 'anthropic', 'google') for a model.
- Configure preferred and excluded providers in Account Settings.
- Enable automatic fallback to other providers if the preferred one fails.

### Video Generation

Generate videos using NanoGPT's video models:
- Text-to-video generation
- View generation status and history
- Download generated videos


---

## Environment Variables

| Variable                     | Description                                             |
| ---------------------------- | ------------------------------------------------------- |
| `DATABASE_URL`               | SQLite database path (default: ./data/nanochat.db)      |
| `NANOGPT_API_KEY`            | Nano-GPT API key for generation                         |
| `BETTER_AUTH_SECRET`         | Authentication secret                                   |
| `BETTER_AUTH_URL`            | Base URL for authentication                             |
| `ARTIFICIAL_ANALYSIS_API_KEY`| (Optional) API key for model benchmarks from artificialanalysis.ai |
| `ENCRYPTION_KEY`             | (Optional) Encryption key for API keys at rest. Generate with `openssl rand -base64 32` |

### API Key Encryption

The application supports encrypting API keys stored in the database using AES-256-GCM:

- **Optional**: The app works without `ENCRYPTION_KEY` (keys stored in plain text)
- **Recommended**: Set `ENCRYPTION_KEY` to encrypt all API keys at rest
- **Migration**: Run `bun run scripts/migrate-encrypt-api-keys.ts` to encrypt existing keys
- **Details**: See [`scripts/README-API-KEY-ENCRYPTION.md`](scripts/README-API-KEY-ENCRYPTION.md)

---

## Database Schema

The application uses SQLite with Drizzle ORM. Key tables:

- **messages**: Stores chat messages with content, role, annotations, and follow-up suggestions
- **user_settings**: User preferences including follow-up questions toggle
- **conversations**: Chat sessions with metadata
- **assistants**: Custom system prompts
- **user_memories**: Persistent cross-conversation memory

---

## Tech Stack

- **Frontend**: SvelteKit + Svelte 5
- **Styling**: Tailwind CSS
- **Database**: SQLite + Drizzle ORM
- **Auth**: Better Auth
- **AI Provider**: Nano-GPT (nano-gpt.com)
- **Runtime**: Bun
- **Container**: Docker

---

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## License

MIT License - See LICENSE file for details.
